Transcription
Speaker 1: Okay, um, to begin with, let me walk you through the interface that we have for now. So this is based off of a survey that we conducted with the community about their concerns about the quality of water, where they find their information and what they think about the information that is accessible to them, and also based on the interview sessions that we've had with you and [community leader] as well.
Um, so I have a few screen recordings to save time. The system is in place; the problem with it is it takes a while to load because we're using LLMs, we need to wait for its response, and we have a huge knowledge base currently. So that takes us a while to find the content that is displayed. That's the reason I'll walk you through with a video for now; you'll access the interface later.
So let me give you an introduction of what the interface itself currently is. So we have a set of questions; these are based off of the survey responses, based on what people are mostly interested in knowing, what questions they usually have. And each question can be viewed from a different perspective. So those perspectives we're calling "frames".
For instance, if someone is interested in knowing what it means by "presence of lead" in their water, then they can try to understand what safety or personal actions they can take—like using filters, getting the water tested—what health impacts it might have, if there are any policies in place to control the amount of lead in water, impact over time as in what the readings look like historically, what has changed, if policies have shown any change in the level of lead in the water, and finally the source of contamination—how it gets into the water in the first place.
We also have this feature where a volunteer can learn about the different analytes. This was mainly based on your feedback regarding joining the team as a high school student and not having sufficient information, and still being confused about a lot of facts that otherwise would be something more general for someone like [community leader].
Additionally, we have features like providing feedback to the content that the LLM is generating, and also to review the content later. Um, so the first stage of the generation process is it looks at the question and, focusing on the frame, it gives you a set of facts.
(Brief pause as she navigates the video)
So, sorry. Let's see if I can move this away. I'm really sorry. Alright, let's try this. So, here's the initial view where you can see all the facts that are grouped based on the type of content it has. You can review these, and all the information is collected from articles that have been published by universities, EPA, and CDC—so that is to ensure that the content itself is reliable given the authenticity of the source itself.
So you can review those, you can provide feedback regarding it, and the system will take that into account when generating content in future iterations as well. So it does not stay only for this session or this response; the same feedback that you provide will be considered when generating any future content.
Community Volunteer: And when it generates the answers based off the question, does it also provide where they got the information from?
Speaker 1: Yes.
Community Volunteer: And with links?
Speaker 1: Yes, okay. There are URL links that I think I have in the next video which you can access. So, the initial content that you saw was very text-heavy and there was a lot of stuff there that was difficult to read. So, that is more for a community leader or a volunteer who actually wants to read the content and dig deeper.
But for a community member, that would be too much of an information and probably not serve the purpose which is making information accessible. So to resolve that problem, we have a second stage of knowledge presentation where we're presenting the information as cards or slides where you have summaries, titles, and each slide is focused on a specific content which is dictated by the slide title.
And you can zoom in to see the content in detail and you can also change the narrative of the content of the slide. This feature is only for a community leader or a volunteer because for a community member we would like the information presented in a specific way, although we do plan to keep them aware of the tone of the message and the level of detail provided to them, which definitely will be controlled by the community leader and volunteers.
So, the ways in which you can change the content is modify the tone itself. So for instance, here we're looking at the message as a caring neighbor would share with the other community members.
Community Volunteer: "What would the other ones look like?"
Speaker 1: "So we have a few other ones, like a city hall translator, which would be more formal, maybe a bit dry. We also have a how-it-works guide, which is more casual and peer-to-peer."
Community Volunteer: "And the levels?"
Speaker 1: "The levels of detail, we have low, medium, and high. We can see how the content changes and expands based on those selections. For example, 'low' might just be a quick summary, while 'high' includes more of that raw data and context we saw earlier."
Community Volunteer: "Can the person [the community member] change it?"
Speaker 1: "So the community members cannot change it for now. This is because we want to ensure the information is accurate and presented in a way that's most helpful and safe for the community. The volunteer or community leader will set the default for the cards to maintain that quality control."
Community Volunteer: "It's interesting that the 'caring neighbor' uses a lot of 'we' and 'our' instead of just 'you'."
Speaker 1: "Exactly, it’s meant to build that sense of community and trust. And if we go to the 'government official' tone, you’ll see it’s more 'the city' or 'the department'—it’s more detached but authoritative."
Community Volunteer: "And for the 'how it works guide' [tone], does it use slang or just simpler words?"
Speaker 1: "Mostly simpler words and a more direct, peer-to-peer style. We’re trying to avoid too much slang to keep it professional but relatable. And then here is the 'Feedback' feature I mentioned. If you see something that isn’t quite right, or if you want to add a specific local detail, you can just click “provide feedback”. This gives you that final 'human-in-the-loop' control before anything goes out to the public."
Community Volunteer: "That’s great. It really balances the speed of the AI with the accuracy of our local knowledge."
Speaker 1: "Exactly. And the last thing I wanted to show you is the feedback mechanism for the LLM itself. If the generated facts are wrong, you can flag them here. This helps us improve the underlying model over time."
Community Volunteer: "This is for the like volunteers, right?"
Speaker 1: "Yes. So you can select a specific one and look at the response. It takes some time because of the knowledge base that we have, which is pretty huge. Also when you change the frames, it actually... okay, it triggers the API call so that makes you wait longer essentially."
Community Volunteer: "Okay. This might update this since you change the frames. So the text box—is there a way to make like the font different? Like if the user has a preferred font or, you know? 'Cause sometimes a lot of older people like they... they have to like, you know, if you plan to put it on the phone, you know what I'm saying?"
Speaker 1: "Um, so this view that you see currently is only for the community leaders and volunteers, because it's very verbose. What the community members will see is the slides. But your concern about the font is actually very valid. That's something we need to include in the slides view."
Community Volunteer: "Okay. And also I think, um, it should just—I guess not be too personal, but taking information I think is important. Like maybe how old you are. I think is an important thing."
Speaker 1: "Demographics?"
Community Volunteer: "Yeah, demographics. Like is that gonna be like a... not a question, but a suggestion like 'Hey, you know, it'd be easier for me to cater to you given your demographic' or just things like that. Just a little, not like too personal, but like just enough, you know? 'Cause if you already say 'Hey, I'm this many years old,' you know, that might be a little bit different. 'Cause information to an 18-year-old might sound different to somebody who's 50 years old, you know?"
Speaker 1: "Yeah, that's true. My concern with that is... it's personal... yeah, they might be a little bit like... yeah, skeptical about providing their personal information and tracking and stuff."
Speaker 1: "Um, so you can see that the cards are changing. That's because you switched the frames, and the new latest contents are being updated. Yeah. So that's more of a user experience thing and we're still working on it. So our focus was mostly on the interface."
Community Volunteer: "So if I was to give feedback would it update immediately?"
Speaker 1: "Yes, yes it will. Also about the links that you talked about—you see those citations? Numbers? They redirect you to the source, the original source."
Community Volunteer: "Oh okay, really good. How long you guys been working on this?"
Speaker 1: "We started right after the... after the interview sessions. I forget, it was the beginning of the month I think. Um, there's actually one more feature that is—if you select more than one card and you want to see how they are related, you can use the 'Learn how selected topics are related' feature."
Speaker 1: "So what that does is summarizes the contents of the cards and then gives you deeper insight about how the information presented there differs. Um, I think there's a problem with this. Can we refresh? I'll take a look at that. Let's try again."
Speaker 1: "Most of the issues we're facing with the summary and all that is the LLM's response is not formatted the way we want it to be, despite the instructions."
Community Volunteer: "You think it's generating too much at one time?"
Speaker 1: "Um, it's not about the length. It's about the structure. So we need the response to be formatted in a specific way, and sometimes it just refuses to listen to the instruction."
This is the transcription of the audio recording 1.2.2.1.m4a. In this segment, Speaker 1 details how visual aids like infographics and charts are used, and how different "personas" (like the Caring Neighbor or City Hall translator) handle data uncertainty. which definitely will be controlled by the community leader and volunteers. So, the ways in which you can change the content is modify the tone itself. So for instance, here we're looking at the message as a caring neighbor would share with the other community members.
Also, the visuals change with the frame—whatever seems appropriate for the frame that we're looking at. So if you remember the first slide talked only about what the most recent readings looked like, which policies were in place and what it means. But when we look at the health frame, it also talks about the effects on your health, what the sources are, along with the data and additional notes to help readers read the report.
So getting back to what I was talking about the tone, there are a few other variations which I'll explain in the future slide. So that essentially changes how the message is structured while keeping the content same. So we're not going to add or remove information; we just present it in a different way, right?
Another level of control that you have when looking at the messages is the amount of detail. So for instance, this is a very brief summary of how the question itself can be answered given a specific frame. Which you can look at for further details which is explanations, or look at the full story—and I have examples for these as well, which I will show in the future video.
Another thing that we have in place is, in addition to presenting the results as tables or cards or charts in general, we also have infographics. Currently, the infographics are all scraped from sources where we get the data. So for instance, this one's from EPA and the content that is presented is a combination from EPA, CDC, and any university-published work.
So how this is working is we look at the content of the message generated. If the infographic seems feasible, we display it so that it helps the reader understand what the message is talking about. And for each frame, we have a different visual to explain the data. So the first two... there were cards in the first slide, but for this one where we're talking about policies that were introduced, we have a line chart.
So what this is essentially doing is—these dots that you see are the readings at that point of time. So this is averaged by the month. And we see a few policies that were introduced during... so say the LCRR, which is the improvements to LCR, was introduced October 2024. And you can always scroll back in time to see what it looked like historically. The same visualization is also accessible in the 'Impact Over Time' frame because we're still looking at what the data looked like historically. I have a few changes that I still need to implement in how the chart is displayed.
And lastly, so for each frame we have a different visualization, but for certain frames like the 'Source of Contamination', we might not always have a visualization that fits the explanation. So since we don't have any data to display here, we rely solely on the infographic. And given the infographics are collected from the sources, if they do not have any picture to explain the content, it's currently missing. So that's something we plan to work on in the next phase, which will be after the..."
Community Volunteer: "Would you ever let the model like generate some images? Or... I would say no 'cause I think the problem with that is the margin of error is... you wouldn't want any misinformation. I would say straight away no from that."
Speaker 1: "Yeah, so that's actually our plan. We're not letting the model generate the content because it's not useful—one, the infographics, and like you mentioned, the level of misinformation that it generates is pretty high. So we're sticking to having a pool of infographics that we generate and letting the LLM pick from that.
The next thing I talked about was the different personas—how the message is displayed. So we have five personas currently and you can see the difference in the personas is how it explains the message. So someone like a 'Caring Neighbor' would have a calmer tone, would help the people understand what issues they're facing, whereas a 'Truth Teller' is more straightforward and just states the facts rather than sugarcoating it or putting it nicely. The tone similarly changes for the other personas.
And another factor that we need to consider when presenting a message is the uncertainty of the message itself. So for instance, when testing is done, the device itself has some limitation. So that needs to be clearly conveyed to the community member. Another part is the data that we're showing is from different regions and that might not align with their zip code or with the location of their community. So we need to express that appropriately. And finally, the sources that we call reliable may not be reliable for the community member. So that's also another uncertainty that we need to handle.
So each persona also handles the uncertainty in a different way. Someone like a 'Change Maker' treats uncertainty of the data as a risk, so that's more critical for them. But someone like a 'Caring Neighbor' just states it—like 'this is an uncertain result'—but does not consider it as something hazardous to the community member.
And that's also why we have each persona by default related to a specific frame. For instance, what we currently have is when we're talking about a health frame, by default the message is formatted like a 'Caring Neighbor' is talking about it. And the main reason for that is we would like the message conveyed, but we do not want any panic among the consumers. Whereas when we're talking about policies, we have a 'City Hall Chancellor' who is more straightforward, talks particularly about system failure, where the gap lies in the system itself, and talks about leverage points, responsibility, and explains the system in more detail.
So to give you an example of how the tone changes when the persona is updated—so we can see that this 'Caring Neighbor' talks about averages in a more casual way of just sharing information, but when we change to a 'Truth Teller', you will see that the message is more straightforward and assertive."
Speaker 1: "...so you can see how the use of averages has been reported differently, and we're using numbers and more specifics when the persona is changed.
We also talked about giving—allowing the users to configure the amount of information displayed to them. So they can either look at the summary of the content, which is L1 level of detail, or L2 level of detail where the matter is explained in a little more detail, or towards L4 where it explains the source of the context, all the nuances of the facts that have been presented to them. And naturally, the length of the message also changes when the amount of detail is updated.
So to give you... you can see this in when you interact with the system, but essentially the length changes and the amount of details provided also updates. Previously it was only talking about lead line services having the problem, but in this more detailed version it talks about where it originates from, how to review the reports, what uncertainties are present and how you can handle it. And then when we go into further detail, there's even more content provided. So it's not just expanding the text, it's also adding information as we go."
Community Volunteer: "So this is what the user would see when they get first...?"
Speaker 1: "Yes, exactly."
Community Volunteer: "So then, like you’ll have like baseline questions on the side that the user can automatically go to—that they... you utilize if, um, the general public, like 'okay this is what I would want to know'. So how does the model respond to like—how does it respond to like questions so, for example, if I was like... 'um, my water is brown, like what do I do?' How would it respond to that?"
Speaker 1: "Yes, so... that part is a work in progress, but this AI assistant you see here—it does not only accept feedback or... but it also accepts open-ended questions. So if you have a specific question like 'Why does my water look brown?', you can enter it there, send it to the LLM, and it should render a similar response. But for now, we're restricting ourselves to the questions that are listed that is based off of the survey response. Although we are still working on the AI assistant part to make it more accessible.
So this is more about how you can interact with the cards when the facts are presented. You can provide feedback to individual cards. So for instance, when you're reviewing this content you see something that is missing here or there's a misinformation, then you can provide a feedback which the system records. There's slight changes in the UI—this was a previous recording which you'll see when you interact with it. So only the content of the card updates.
But if you see that none of the content that is rendered or made available to you makes sense, or if you want more cards to be added, then you can always provide a feedback using the AI assistant. There are some other minor things in the interface itself to improve usability. So for instance, like I started with, the system takes a some time to render the content or get fetch the information, so we have this... a set of facts..."
Community Volunteer: "Oh, nice."
Speaker 1: "Yes. So while the message is loading, some facts are displayed so the user stays engaged. And this is closely tied to the question and the frame in which the user is interested in. Currently we have a fixed amount of facts... we just have the feature in place but the data is limited. So there are certain facts for all the community questions, but for the analytes we're still working on collecting the data.
And also yeah, the fact does not stay the same throughout the duration but it changes. So to begin with it talked about something PFAS concerns that can include both specific compounds and stuff, but after around 15 seconds the message changes so that the engagement remains.
And yeah, so potentially a user may not have some feedback to give but they just like or dislike the content, then they can use the buttons to give a quick feedback about the content itself, which again is recorded and considered in any future responses. Additionally, just to keep track of what messages the user has gone through previously, we have this bookmark feature. So you can select a few cards or messages from a specific question that you find interesting and when you switch to a different context, which is essentially a different question, you can always go back and review the same in the 'previously viewed messages' all together. So that's like a summary of everything that you've browsed through so far.
So here's what the interface looks like. Feel free to interact with it. Let's keep it open-ended so that we can capture as much feedback as possible. Just a heads-up on the interface itself—since we're using LLMs, the GPT model that we're using currently is acting a little uncertain, so for some questions it's rendering empty responses. So we can focus on the ones that work for today's feedback."
Community Volunteer: "Awesome. Also this is why it was loading right now—the... so this is like loading right now 'cause I already asked the question?"
Speaker 1: "Exactly."
Community Volunteer: "This is for the like volunteers, right?"
Speaker 1: "Yes. So you can select a specific one and look at the response. It takes some time because of the knowledge base that we have, which is pretty huge. Also when you change the frames, it actually... okay, it triggers the API call so that makes you wait longer essentially."
Community Volunteer: "Okay. This might update this since you change the frames. So the text box—is there a way to make like the font different? Like if the user has a preferred font or, you know? 'Cause sometimes a lot of older people like they... they have to like, you know, if you plan to put it on the phone, you know what I'm saying?"
Speaker 1: "Um, so this view that you see currently is only for the community leaders and volunteers, because it's very verbose. What the community members will see is the slides. But your concern about the font is actually very valid. That's something we need to include in the slides view."
Community Volunteer: "Okay. And also I think, um, it should just—I guess not be too personal, but taking information I think is important. Like maybe how old you are. I think is an important thing."
Speaker 1: "Demographics."
Community Volunteer: "Yeah, demographics. Like is that gonna be like a... not a question, but a suggestion like 'Hey, you know, it'd be easier for me to cater to you given your demographic' or just things like that. Just a little, not like too personal, but like just enough, you know? 'Cause if you already say 'Hey, I'm this many years old,' you know, that might be a little bit different. 'Cause information to an 18-year-old might sound different to somebody who's 50 years old, you know?"
Speaker 1: "Yeah, that's true. My concern with that is... it's personal... yeah, they might be a little bit like... yeah, skeptical about providing their personal information and tracking and stuff."
Speaker 1: "Um, so you can see that the cards are changing. That's because you switched the frames, and the new latest contents are being updated. Yeah. So that's more of a user experience thing and we're still working on it. So our focus was mostly on the interface."
Community Volunteer: "So if I was to give feedback would it update immediately?"
Speaker 1: "Yes, yes it will. Also about the links that you talked about—you see those citations? Numbers? They redirect you to the source, the original source."
Community Volunteer: "Oh okay, really good. How long you guys been working on this?"
Speaker 1: "We started right after the... after the interview sessions. I forget, it was the beginning of the month I think. Um, there's actually one more feature that is—if you select more than one card and you want to see how they are related, you can use the 'Learn how selected topics are related' feature."
Speaker 1: "So what that does is summarizes the contents of the cards and then gives you deeper insight about how the information presented there differs. Um, I think there's a problem with this. Can we refresh? I'll take a look at that. Let's try again."
Speaker 1: "Most of the issues we're facing with the summary and all that is the LLM's response is not formatted the way we want it to be, despite the instructions."
Community Volunteer: "You think it's generating too much at one time?"
Speaker 1: "Um, it's not about the length. It's about the structure. So we need the response to be formatted in a specific way, and sometimes it just refuses to listen to the instruction."
Community Volunteer: "What if the user wanted to know more about the facts? Like this right here. Like what if they saw something they wanted to ask like... about this. Like how would they just put it right here? Like 'Tell me more about this...'"
Speaker 1: "Yeah, so that would be... we have different ways of interaction, because currently the facts are static and they're just to give like a... like a byte. Essentially the question that they've asked should answer the questions they have regarding the facts."
Speaker 1: "It's taking too long... do you mind if I take a look? I think something happened to the backend."
Speaker 1: "Wait a while to generate these responses. I need to add some text... like a disclaimer, please do not switch."
Community Volunteer: "Do you mind if I respond to a text? Go ahead, no problem."
Speaker 1: "I hope it doesn't... I just fixed it last night. We were having trouble yesterday—for some reason the LLM just refused to respond, and I tried fixing this with some prompts. Go back. Let's try out the other features for now."
Community Volunteer: "Let's do a simple one. Like what? This right here is like 'alpha testing' the AI assistant, right? Yeah, I won't touch that. So what does this respond to right now? Just concerns and feedback?"
Speaker 1: "Yes, so any feedback you provide regarding the facts or the slides as a whole is entered through the AI assistant interface and it makes changes to it."
Community Volunteer: "So this'll look different for a community member?"
Speaker 1: "Yes. For a community volunteer, this is the screen that they'll see. For volunteers and leaders, it's this interface. For the community members, the emphasis will be on the AI assistant, considering the fact that they'll have more specific questions and will not just want to explore what is made available."
Community Volunteer: "So the community member won't have access to this?"
Speaker 1: "No, not all the features that are here."
Speaker 1: "Do you have any comments about the interface so far, apart from the glitches that we're facing?"
Community Volunteer: "No, I think honestly like... it’s perfect. I think for community members, like at least in that sense for this, it’s like you can coach the other person into 'Hey, if you have a question like I got you' because with community volunteers... community volunteers can be community members. So a big thing for me is like a community member who’s unfamiliar with this will go in and then if they have questions, obviously they’ll be at [community-based organization], so any other community volunteer who is familiar can help them out with this. So I don't think it’s that hard for people to understand. But I think it’s important to note that like the transition from a community member to a volunteer... like how that would be... in that moment."
Community Volunteer: "So the sources of contamination will generate with this like automatically?"
Speaker 1: "So although a frame helps you focus on a specific topic, the other frames have an influence as well. So for instance, if you want to know about personal actions, you need to know where it comes from. So that information is also displayed to give an overall picture. I just clicked 'Style this content for the community'... so it generates the slides that I showed you in the videos, which is a better formatted view of the same message. Essentially, when a community member interacts with the system and when they have the question that they would like to ask, internally what happens is the facts are generated and then the styled content is generated, but the user-facing part of the interface directly shows them the styled content."
Speaker 1: "So it lists all the... all the contaminants that could affect them, what the levels currently look like, what the thresholds are, what rules... yeah, that's something we need to work on. But if you click on the interface, if you click on the card... you can get a better view. You can also select the... click on the URL to go see more detail that EPA has released regarding the policies."
Community Volunteer: "Do you guys plan to allow them to like ask about the sources? Like where to navigate to? Obviously they can click the link, but like say 'Hey, you know, is there a specific section?'"
Speaker 1: "That would be very useful. We need to consider that for future features."
Community Volunteer: "So they're already learning to navigate the AI, so what about navigating the websites? Like the thing is like for anything you have to just treat it as if the person is just brand new to AI and, you know, some things... and a lot of people are. But, working in [city], like I have seen a lot more older people like be like 'Oh, just ask ChatGPT' and I'm like 'Oh, you guys actually know how to use it'."
Speaker 1: "That’s interesting to know."
Community Volunteer: "Yeah, so some people are actually... 'cause I work at[company] in [city], so a lot of the time they'll be like 'Oh, like I'll just ask ChatGPT' and they'll be really old and I'm like 'Oh yeah, like I'll just ask them this question' and it's actually... I've seen a lot of people use it more and more. Probably because of grandsons and children who don't want to... not not deal with their grandparents, but like 'If you have a question just ask ChatGPT instead of me'."
Speaker 1: "We were very skeptical about the learning curve of how people would interact with the AI system, but knowing that would really be useful because they can ask the AI assistant to navigate. Our idea behind showing the facts first and the content is so that the community leader and volunteer have nuanced control over what content is being presented. So if there’s any misconception or factually incorrect facts, then they can provide a feedback and then make sure that is communicated."
Community Volunteer: "So this 'Provide feedback' will be only for the community leaders?"
Speaker 1: "Yes, for the community leaders and volunteers. For the members, it will just accept more queries and help answer that and uncertainty."
Speaker 1: "The feedback log is where every feedback that the users have provided—it's mostly junk right now because we've been testing it, but all of these factors are considered when responding. So you can see for which question the content was generated..."
Community Volunteer: "Wait, so this says 'Safety and Personal Actions' but like on here it's 'Effects + Actionable Items'?"
Speaker 1: "Oh..."
Community Volunteer: "Yeah. And then, okay yeah, and then that said 'Policies' and the other one says 'Protective Measures'."
Speaker 1: "Yeah, so it's... the difference actually is the labels that are shown and internally how it's been used. So that was a mistake on the labels. Um, for the visuals, you will have to style the content so it does not show up in the facts."
Community Volunteer: "Okay. So... actually no, I want to do the... where’s like the 'Neighbor'? That’s at the top, right?"
Speaker 1: "It's also in this 'Style' field."
Community Volunteer: "Okay, I'll do 'Style'. Oh, can you do two at the same time? Like while it’s loading, can I click 'Style this concept' and it give me both?"
Speaker 1: "Uh, no, that would actually be a problem because, like I mentioned, we want the facts to be rendered first."
Community Volunteer: "Yeah, you want the facts to appear first, I understand. So what’s gonna show up now if I clicked it?"
Speaker 1: "Uh, it’ll show up the facts first, and then it will be the styled content. But it's highly likely that it’ll break because it's more of a sequential process. It might trigger the process although without complete information."
Community Volunteer: "Maybe there should be... yeah, if there was a way to not make it accessible until the... like once it drops down then at the bottom say 'Style this concept'."
Speaker 1: "Yeah, so this shouldn't be available until the content's actually generated. There are quite a few user experience things that we need to fix here."
Community Volunteer: "Yeah, but the content overall is good. It’s not like anything... it’s just, you know, stuff that takes time. On that note, the content that you read—do you have any comments about the facts that it is presenting?"
Community Volunteer: "I'm looking... okay, very quick. So far I feel like... the content is good. Like so this right here, right? It would be confusing, but then you do the 'Style the content for the community' and then... so it already solves the problem. It’s not like there’s an issue. And plus I think the 'Community Volunteer' one is going to be a lot more informational than the one that’s for the community members. So this makes sense. I wouldn’t really have like any critiques in terms of content because at the end of the day, it's people who are already on the inside, so some things already look familiar and things that aren’t familiar will be explained by anybody else in person or, you know... But if they want to do their own research, they still have the 'Style the content for the community' part."
Speaker 1: "Um, do you have any comments on the reliability of the information itself?"
Community Volunteer: "So, based off what I heard, it's not making—it’s not generating anything new. The content is based off of what you’ve uploaded already—so EPA and reliable sources—so I don’t think it’ll have anything like unreliable. I feel like the credibility is there. I think the main thing is just gonna be the AI assistant. Like just making sure that like if I say 'Oh, if I boil my water will it be safe?' or 'Are there safe levels to lead?' or 'Is this amount of lead okay?' and if the AI is like 'Yeah, it is' and it’s not, then that’s a problem, you know?"
Speaker 1: "Right. It's mostly about how we inform about the uncertainty too."
Community Volunteer: "That’s the main thing. I mean those are the main questions, so like: 'My water is brown, what do I do?', 'My water tastes funny', 'Is it okay for my kids to drink my water?', 'This is my zip code—do I have lead lines running through my house?' That's also an important thing—information in terms of like geography. So like 'Is my area more likely for lead?' or based off of findings provided by [community leader] or the data, you know, 'Am I safe?' Obviously without compromising personal data and addresses and things like that, but you get what I mean."
Speaker 1: "Okay. Okay, so look—it did generate the styled content in terms of that. So you can scroll to the next slide as well."
Community Volunteer: "Like that? Yep."
Speaker 1: "Yeah. So you have that bottom navigation as well and when you scroll lower... that will switch through slides."
Speaker 1: "It seems the content changed because we clicked the button twice. So it updated, it looks like. We essentially would like to replace the image suggestion with some infographic that we've collected."
Community Volunteer: "And then if they have a question about the infographic, you know, how it responds is also important. I just want to see how it's different from the other one. Which one do you think is going to be like the most used one?"
Speaker 1: "The most used one? Um, our expectation is it will depend on the frame itself, because each message needs to be conveyed with different levels of sensitivity."
Community Volunteer: "Oh yeah, 'cause you did say that like 'Protective Measures' or like 'Policies' would be like a City Hall worker."
Speaker 1: "Do you think that would be the case in a real-world scenario?"
Community Volunteer: "What do you mean, like...?"
Speaker 1: "So, when you're doing the field visits, and when you see/hear questions regarding a specific frame, would you respond to it differently, or would people react to your response when you put it differently?"
Community Volunteer: "Yes, I think how you convey the information is important. If you come into the house like—not a robot, but as if you were an official or you know, it was just a job—it just makes it a lot more... not standoffish, but it's like you feel like this is the resident and then this is you. So you don't feel that communication. If you just tell them 'you have this amount of lead, this is what you need to do' and then you just leave, it’s like... they'll take it seriously, but I feel like the message doesn't come across as much. But if you come in like a caring community member way, and say 'Hey, this is what we found, this is what it means for your kids' and you show that care, I think it's important and it's that it would be received differently. You know, I've had people who care about me come to my home and test my lead, and they're doing it for the reasons of caring, not because of money and things of that nature."
Speaker 1: "Do you think that would impact their engagement with an organization like the [community-based organization]?"
Community Volunteer: "Most definitely. I think one of the biggest things is if they come inside—we've had people come in and be like 'Hey, you know, you tested my house, it was a great experience, it was fun' or 'how did you enjoy it?' or you know, they'll say it was fun, they came in and it was easy. But I do think it changes it. I think if we said we were from the city, they would be like... like on us like this, like following behind us the entire time. Or if we weren't friendly or just like very sort of mechanical about the way we were going about things, then it'd be a lot less trust in the things that we do. But if we just show 'Hey, like... obviously there's a mistrust because we're kids, that we're like young,' but we're like 'No, we know what we're doing' and we like educate them a little bit about the process that we're going through and you know, it all worked out. But yeah, I do think it's important, especially in how they interact with NWC."
Speaker 1: "Let me just check if this isn't broken. It's not supposed to take this long for the change of tone. There was some kind of error there. Let's try it again. Let's use Lead. Are you okay with that?"
Community Volunteer: "Yeah, that's fine."
Speaker 1: "Just so you get a feel of what things look like. And weirdly, the more I use it, the more the LLM tends to refuse to respond that I've observed. So probably there's like a session that goes over... that's been something we've been struggling with lately. Um, do you think this system would change how you've been doing like events in person at NWC? And how you disseminate the knowledge, how you interact with the community? The trust aspect of things?"
Community Volunteer: "Specific to this, I think: one, it'll make volunteers a lot more knowledgeable and share their understanding with others based off of a reliable source. But also I feel as if, you know, we should like soft launch it at our events. We should be like 'Hey, you know, we also have this... if you have any questions or concerns, we do have a website but we also do have an application where you're able to learn more about lead'. We could even have information sessions about talking about how to use it, things of that nature. So I think it definitely would change things. And it makes it a lot easier in terms of like just getting the information out there. 'Cause anything helps really—before we had email blasts and posts on Instagram and Facebook, but now you have something that is readily available for anybody to use. So I definitely think it'll change things."
Speaker 1: "Would you like me to change something? Or if you want to read through it first, that's also fine."
Community Volunteer: "I see right here: 'Because we do not know the age of your home's pipes yet, we cannot rule out lead...' and then they'll talk about the age of their home."
Speaker 1: "Yeah, so it just mentions that there's uncertainty in how we're reporting it, so we cannot directly say it. But if you look for more explanation, it should provide more information about that as well. So you have the control over the amount of information being displayed."
Community Volunteer: "How do I make it more?"
Speaker 1: "Do you see that slider up there? You can get to 'More explanation'. I think you selected the first one... Oh, you have to slide it. No, you can click on the title as well. So if you scroll down, there's more details about what you can do to get to know that. Those are highlighting the terms—so eventually what we want to have there is when you hover over it, it explains what those terms mean."
Speaker 1: "So for instance, this matches what you see in your home plumbing... or what does that refer to? Like..."
Community Volunteer: "Do you know what the connections look like at your home? That... a lot of people probably wouldn't know that."
Speaker 1: "Yes, so..."
Community Volunteer: "And then also right here, right? It’ll give this, but then it's like... the first one will be like 'But if I have lead in my water, should I be drinking it?' or 'Is there a safe amount of lead?' or 'How do I test?', you know? So this... I feel like it would be misleading a little bit... on like a regular bystander. Like obviously us is different, but I feel as if a regular person—or even the volunteer member themselves—might be like 'Wait, so should I?' 'Cause I know this is for the volunteer, but will this be how it'll be displayed to the regular person too, or no?"
Speaker 1: "Uh... currently, based on the current implementation, yes. But you have other slides that can help you explain it better. So your concern was: 'Can I drink it? Should I even drink it?' So there is like immediate steps that you can take... while [the water] matter... what would be your first step, which is essentially checking for the source. So you can always slide to the other slides and look at more information."
Community Volunteer: "I'm just saying for the sake of the AI model... because action versus inaction just depends on obviously the person. But it's like... you're telling me to drink the water, but then I still don't know anything. So essentially we need to better report the uncertainty."
Speaker 1: "Yeah, but that just comes with time because it's just hard... it's hard to know anything without the user—without prompting the user to give anything without making it feel too personal. Like I'm... like when the user wants to give information, it should be because they want to, not because, you know, you forced them to. Yeah, but it should just be questions of like 'Um, I can't tell you anything until I know more. If I don't know more, for now the safest option is to...' and then just..."
Community Volunteer: "So always provide the safe—in my opinion—the safest option is always the better one because it doesn't leave any room for like nuance, like interpretation. It should just be like 'Okay, no, this is what you should do.'"
Speaker 1: "Um, since we have the feedback feature implemented, we do expect a lot of these nuances to be handled over time as we get more feedback. Do you want to explore the tones?"
Community Volunteer: "Should work? Yeah."
Speaker 1: "It takes some time."
Community Volunteer: "That’s actually really cool though. You guys did a good job."
Speaker 1: "Thank you. The interviews were actually very helpful in coming up with the design and what we should consider."
Community Volunteer: "I’m glad."
Speaker 1: "So... Truth Teller."
Community Volunteer: "It’s a lot more serious than the Caring Neighbor. Okay, I like this. This is good. Do you feel as if this would be easier to read to somebody like a bystander? Like a volunteer? Do you feel as if like this is like the final, I guess, like...?"
Speaker 1: "Yeah, that... that will be the... the end of the pipeline kind of, after all the content generation."
Community Volunteer: "Last thing. So you can't bookmark these?"
Speaker 1: "Uh, no. It would be good to have those though."
Community Volunteer: "And if I bookmarked a card before and then we transitioned to this, and then I try to bookmark this, will they still be together or would the bookmark disappear?"
Speaker 1: "Um, the bookmark stays as long as the session is open, so anything that you bookmarked previously is available."
Community Volunteer: "Okay. And if I wanted to... so after I did the generation of this, right? So how can I get back to, let's say, this? Like what if I want to expand on this more?"
Speaker 1: "Expand on...?"
Community Volunteer: "So what the bookmark shows you is a details of the information that was presented in that card. I don't know if I got your question. Like if you have any further follow-up..."
Community Volunteer: "Yeah, like if I had a follow-up about this—like the bookmarked card—then I'd have to go to the AI assistant and then I guess..."
Speaker 1: "Eventually, yes, you can go to the AI assistant and then ask a question about it. Currently we don't have a feature on that yet."
Community Volunteer: "Okay. So now this will go back to the cards, it won't do the styled content?"
Speaker 1: "Do you think it would be helpful as a volunteer to directly go to the cards?"
Community Volunteer: "Yeah, I think the cards are the easiest thing... starting out. And then if you want to, you know, expand on it, then you can. But I think the cards are pretty useful. 'Cause a lot of the volunteers are like younger, at least based off the last time I was there—'cause they had like the anniversary thing and I went and there was a lot of younger folks. But as for... is there a way you can change the language yet or not now?"
Speaker 1: "Um, we don't have that on the interface yet, but we've been considering different languages, especially Portuguese and Spanish—the biggest thing probably. Okay, let's style the content to go see the slides. I just want to make it... so this is actually the view that you see in the bookmarked content."
Community Volunteer: "Is there a max amount of bookmarks?"
Speaker 1: "No, you can do as many."
Community Volunteer: "And how many cards can—would you be able to select for the—just two?"
Speaker 1: "For the summary, there's at most two currently."
Speaker 1: "So, what's your impression on the ability to change the tone of the message? Do you think it's what you expected?"
Community Volunteer: "Yes. I mean, I've only seen two so far. I'm going to look at them more here at this point. I'll get back to you after I do at least three. But so far, I mean, I guess the 'Caring Neighbor' is a lot more gentle than the [other tones]... so it does do its job. But as you said, it doesn't generate new content, it just says it in a different way?"
Speaker 1: "Yes."
Community Volunteer: "Have you noticed that it’s generated new content before, or is it okay?"
Speaker 1: "It only generates new content if you expand the level of detail that you..."
Community Volunteer: "When you do the sliding?"
Speaker 1: "Yes. Otherwise, it's just the same thing. So apparently this assumed that a 'Truth Teller' would also explain how the contaminant gets into the water."
Community Volunteer: "Do you feel as if we should limit the tones per... like if we're under 'Health and Well-being', would we change it from a 'City Hall Translator'?"
Speaker 1: "So currently, the tone of the message is not set per frame. It's more defined from the backend, because we do not want someone to influence people using the tone. So we have that based on the research. Having as many tones as possible, I think, is a way for volunteers and community members to explore."
Community Volunteer: "Do all of them generate this image?"
Speaker 1: "We can control this as well, but I need to see why it's doing so."
Community Volunteer: "Yeah, because I think the 'Caring Neighbor' didn't generate anything, then when you changed it, it did. But maybe I guess the tone changes that—if it feels as if it needs this in order to..."
Speaker 1: "Yes. So the following tones that you selected are more trying to show you: 'this is where the problem is and you’ve got to do something about it.' Let's do the 'How it works' part."
Community Volunteer: "I want to check this one too."
Speaker 1: "No, you can test it out. It's just the facts that it... the loading screen, did you know cards? That's the only thing that does not show up. Everything else should work as expected."
Community Volunteer: "So it's saying the same thing but then just in a different way. I think the 'Truth Teller', this, and then the 'Change Maker'—I think it's kind of limited by this infographic. Like it’ll all show the infographic and then kind of just basically say the same thing, which I guess is the point, but I don't know. Let me try this."
Speaker 1: "So it's easy, it says 'no facts available'. That's the only thing that's a work in progress. Everything else internally should work as expected. Is there any specific analyte that you would be interested in as a volunteer?"
Community Volunteer: "Fluoride, pH, and then PFAS—probably the biggest things. Everything else I... Anything that anybody can't pronounce, they're probably not going to... they'll be like 'I don't even know what this does'. And nickel, yeah."
Speaker 1: "I think this will work based on... if you want to try."
Community Volunteer: "Let's see."
Speaker 1: "Okay, there we go. Surprisingly it works for some things and not the other. So it summarizes the content from the two [cards] and gives you deeper insight. You can unselect a card if you want to."
Community Volunteer: "I was just checking for like the..."
Speaker 1: "The URL? Yeah, that shows up."
Community Volunteer: "It gives you like a long form."
Speaker 1: "Yeah, so it's..."
Community Volunteer: "It clearly looks like it’s more context-based, but then the issue that I see is like if it's too long then... I don't know."
Speaker 1: "Maybe not long, but some gap in information is highly likely. I'll also try the feedback mechanism."
Speaker 1: "It's currently disabled because it's generating."
Community Volunteer: "What is the feedback like? Per session or is it just based off of everything?"
Speaker 1: "Feedback... it stays, it persists. It's not per session. I had some error fetching it slightly."
Speaker 1: "Did you notice any concerns from the community members about the presence of parasites in the water or microbes?"
Community Volunteer: "No, I don't think anybody was concerned about anything living inside of their water. I feel like the biggest concern—because it was a lead crisis and that was like what was the biggest thing—and that's obviously what the biggest concern was. But another important factor to consider is like, we're not just there for lead, we're also there for, you know, other contaminants. So I guess as time goes on and more people know then... you know, there's more of like an emphasis on the things besides lead. But um, parasites and microbes... I mean, I feel like the concern... it might become a new concern like, 'Hey, I didn't know that that's a possibility,' and they might look into it more."
Speaker 1: "If it works, press [the button]. Yeah."
Community Volunteer: "Yeah."
Speaker 1: "I see a lot of people get confused by that. That's actually my system configuration that you need to press."
Community Volunteer: "I mean the press would be better anyway, because I think if you had the slider, you could just go back and forth and that might... that might not be as good."
Speaker 1: "Um, so you came across features like providing feedback regarding facts itself, and even for the tone and the level of detail you can actually provide feedback. Um, so do you think this would actually create... not create—there already is an invisible labor that goes into the system for the community leaders and volunteers to make sure that the facts are correct so that the community members consume um valid information. Do you think that would be a problem in the future as the amount of knowledge increases?"
Community Volunteer: "Like a problem with like um people providing feedback? Like over time?"
Speaker 1: "The amount of effort required to provide feedback."
Community Volunteer: "Oh, um. I mean, I don't—I don't think so, because it's not like you guys are relying on the 'provide feedback' feature in the way where, you know, it's like, okay, we need people to actually—you guys aren't going in with like the mindset of, okay, the 'provide feedback' is going to carry our project. You're just generating the content and if the content maybe is wrong or there might be an issue then you just provide the feedback. As more content gets, you know, disseminated out the system, there might be more room for feedback and that's okay. I think that's a part of the process. And then it only takes one person to be like, 'Okay, this is the feedback I have,' and then that's it. So I don't—I don't think that'd be an issue, in my opinion. I think it's a great feature to have."
Speaker 1: "And given the fact that a volunteer would also be able to provide feedback... if someone is, say, tasked with providing feedback, reviewing the content from that perspective, would it be like a hassle?"
Community Volunteer: "Oh, if somebody was given like a role to just strictly provide feedback? Just to make sure everything is... I don't think that would be the problem. I mean, I think it would be great. I think um... but at the same time, like, you don't want just one person providing feedback because um, you know, the experience is universal, and then it's like some person might disagree. So if you had two people, it would be preferred if they were to be assigned to work on providing feedback. That way you can bounce ideas. But I think feedback should be like, you know, especially with like the community leaders... community leaders' feedback should not take priority, but you know... what I'm saying. Like the volunteers should not approve—maybe approval—but like, I guess in a way like the feedback should... there should be like a system check. I don't know how to describe it."
Speaker 1: "Makes sense, actually."
Community Volunteer: "Yeah, because you don't want—if everybody gives feedback, then it's like it's not even the original thing anymore, you know? Just trying to—you can't cater to everyone, in a way."
Speaker 1: "Yeah. So this... I tried to go to 'full story' and then... it's probably taking a while to generate the content. Because this one that generates more content is actually a different model and seems to be more reliable than the first one."
Community Volunteer: "Which one? The first one?"
Speaker 1: "No, so we have two different models: one that generates the facts and one that organizes the content. So the model that organizes the content usually is more reliable because it does not give empty responses. It's only the generation one that acts up sometimes."
Speaker 1: "Is that a big concern about the feedback? What do you think the problem would be—like just too much feedback or...?"
Speaker 1: "Uh, no. Where I'm coming from with this question is, would people want credit for providing feedback? Oh. Ah."
Community Volunteer: "Um, I don't think so. Because the point—the whole point of the feedback is, you know, you're helping the community. I don't think anybody would want credit for, you know, trying to make the, you know, model better, in my opinion. And if they were to want feedback—I mean... I'm not going to say it wouldn't have much value, but there would be no point, in my opinion. Like if somebody came to [community leader] and was like, 'Hey, I did a lot when it came to feedback, you know, should I be compensated or should I receive credit?', [community leader] should say no. Because this is a work in progress and the point of the 'provide feedback' is to provide feedback and that's it. You know, it's not like you're making the entire model. Nobody's sitting here and testing it, you know? But if it was a job, it would be different."
Speaker 1: "Right. That makes sense. What my understanding at least was, the more effort that people have to put in, the more they would want credit given the amount of effort they put in. So we were just curious, should we give them credit for providing feedback?"
Community Volunteer: "I think it depends on the level. I think if it's excessive, then maybe if one person spent an hour just giving feedback, then it's like, okay, then as a tester, I don't know, that'd be something they have to work out with [community leader]. But I doubt anybody would be on it this long in order to provide like a lengthy amount of feedback."
Community Volunteer: "Okay, so once it generates... would it be just this long or if it's shorter shouldn't it be like... just a design choice, I guess?"
Speaker 1: "Yeah, it gets more confused if we change the size of the card in a specific row. So it just follows the longest one."
Community Volunteer: "Oh, okay."
Speaker 1: "So we're trying to make it like a smaller card with little information and then you can expand if you want to."
Speaker 1: "And if I do style content, then it'll bring up a lot more numbers regarding this, if relevant. It's just making the information more readable for the users."
Community Volunteer: "Do you feel as if sometimes the content between these merged together at all? Like something from 'Protective Measures' might be a little bit more aligned with 'Health and Well-being'?"
Speaker 1: "Yeah, that's possible. So mostly for the 'Safety and Personal Action', it's more like an overview rather than focusing on specific frames, so that tends to get more content from all the other frames. Whereas for 'Source of Contamination', as you can see, it’s just the overview and then focuses on that specific frame."
Community Volunteer: "Do you think it'd be effective... like let's say they're on 'Source of Contamination', do you think it'd be effective if it was like 'If you'd like to know more about this, then go to this [frame]'? Or should it just expand while inside of here?"
Speaker 1: "The idea is to have everything in one place so people don't have to switch a lot. So if there's something from 'Protective Measures' that is relevant under 'Source of Contamination', it should show a different card there with the color that matches [that frame] essentially. We want every message to be self-contained; anything that a user would want to know should be there."
Community Volunteer: "What are your biggest concerns with the model besides what we’ve already spoken about today? Is there anything else that you think would be a problem for users?"
Speaker 1: "To be honest, when we allow open queries—and as the knowledge base grows—my concern is how will we make sure the entire context is considered when generating a response. And we just don't want it to link A and B and come up with a C that is actually not relevant to that. That’s a big challenge."
Speaker 1: "If you’d like to see the charts then you can go to 'Protective Measures' or 'Impact'. I’m not sure if it will show up for the question that you have selected... but if you scroll on this, you should be able to see the historical view—like what it looked like in the past."
Community Volunteer: "So what are you guys' next steps? Just to keep on improving this?"
Speaker 1: "Yeah, we definitely need to improve the knowledge base that currently exists. We're talking with [community leader] to get more data that is in their repository that could help this. Then there's the user experience—trying to speed things up, reduce the blockers."
Community Volunteer: "So this [volunteer interface] will be the first one that gets finished and then the AI assistant for the community members will come after? And then mobile at the end?"
Speaker 1: "Yes. We want the system working first and receive feedback. Mobile will be at the end because I feel like mobile will obviously be the most popular thing—not everybody has access to a computer, but everybody has a phone. If we go for mobile, we definitely need to focus on releasing an app."
Speaker 1: "I’m actually noticing a pattern here... I’m just looking at the source. Yeah, that’s something I need to work on. We actually have a better infographic that would fit this message, I’m just confused why it’s using this one."
Community Volunteer: "Should I provide feedback?"
Speaker 1: "Yeah, you can actually. [Feedback]: 'Infographic is not relevant.'"
Speaker 1: "It should re-render the content once the change is done, but meanwhile you can still explore the other slides."
Community Volunteer: "Should I click this? It messed up, right?"
Speaker 1: "Yeah, because that's an empty card."
Community Volunteer: "Can you go to 'Overview'?"
Speaker 1: "There's an error in the connection, you see?"
Community Volunteer: "Oh, connection. So what would I do, just...?"
Speaker 1: "Your message will be saved; it will be considered in the future iteration, but just for now, the content is not updated. If you scroll on this, you should be able to see the historical... like what it looked like in the past."
Community Volunteer: "Copper."
Speaker 1: "Yeah, because that's relevant to why... the water [quality]."
Community Volunteer: "And also apparently pH is relevant."
Speaker 1: "So if I said that, then if I...?"
Community Volunteer: "If you change anything, it should consider that content later. Maybe you can change the frame or something? Yeah, that should stay the same."
Speaker 1: "Technically it should, since the feedback is recorded already, but that's something else I need to look into."
Community Volunteer: "Try refreshing?"
Speaker 1: "I think this is taking a while. You can still access the other slides... because you're editing only one slide here, you should be able to... No?"
Community Volunteer: "No, 'cause if I change the tone, wouldn't that change everything?"
Speaker 1: "It should, yeah. But you can still see the data because there's no content to be updated. But for everything else, it's updated. Yeah, that's proof of consistency."
Community Volunteer: "But the same dialogue is... oh, that's why, yeah. So: 'Policies', 'Health', but it says 'Policies' and 'Protective Measure' [on different labels]."
Speaker 1: "Oh... it had some issue generating. Just refresh, maybe that'll take that into consideration. Your bookmarks will be lost when you refresh. Yeah, that's the session end."
Community Volunteer: "So we're at 'Taste'... and then we're in 'Protective Measures'. I can change that; it'll update eventually."
Speaker 1: "Now that you've looked at a few [pieces of] content that are available, is there something else that would be interesting that's not accessible here? Something frequently asked by the community members or something as a volunteer that you'd like to learn?"
Community Volunteer: "Besides... frequently used metrics by the AI, like listing them to be explained or anything right here on the side somewhere that they use a lot—just for understanding. I guess like... when they see the numbers, just to make it a lot more digestible for them. They see this and they're like 'What is LCRR?', 'What is...', you know? All of this is here, right? But... I don't know, maybe like 'frequent ones' that they just have on the side that they use a lot."
Speaker 1: "Something like a dictionary?"
Community Volunteer: "Yeah, in a way. Like an index that I can refer to over here. Okay."
Speaker 1: "We're still doing that. I think we basically covered everything. Thank you so much for interacting so much with the system, actually, and I apologize for the glitches."
Community Volunteer: "Oh no, it's fine. That's the whole point. That's what I expected—you’ve got to come with glitches."
Speaker 1: "Do you have any feedback or suggestion for the system as a whole?"
Community Volunteer: "I would say I would just wait for further development to be honest, because it's just in a testing phase right now. So there's not much feedback to give in terms of like... you already have all the information here, it's just having it work and making it run like that."
Speaker 1: "Do you have any comments on the learning curve of the interface itself?"
Community Volunteer: "In terms of people in... I mean, it's not like it's anything—to me, it's not like it's anything hard—but I would say for the average community member... it'll just be a lot of... it's going to be things that the AI assistant is going to solve. So like 'What does this mean?', the AI assistant will solve that if somebody asks that, or the community volunteers. Like 'What does this mean?'—it's already solved by the AI. Um, what else? Just... yeah, overall that. And then infographics—that's... you're already making the improvements on that to learn more. The links to the thing—that worked fine. I guess how to navigate the links... I mean, sometimes people click this and then they have to scroll like 'What am I supposed to look at specifically on this page that you got your information from?' Um, what else? I don't know. Yeah, I mean... I think it's fine, I mean just design stuff. Remember the font thing—like, you know, people can't see or if they feel as if they need to be bigger. And then how it looks... like this is easy for me to look at, but I don't know if it'll be hard on the eyes for somebody else. So that comes with changing the way the information is like generated. But this should be easy enough for like the average person in my opinion. But as I said, there's a lot of older folks and a lot of younger folks that might be like 'I don't even know what this is', but I think that's like the biggest thing. And then as for these [analytes]... I would say, yeah, they're good, but just a high doubt that anybody would check these out in my personal opinion. Like... yeah, I don't... I doubt a lot of people would be like 'Oh yeah, I don't know'. I think this is good though, in the sense that if it's referred to—like 'Hey, just if you want to know more about this then we have an entire selection of analytes for you to check out'. 'Cause then if you just generate it, then it's just like it's redundant. So just look at this. But I guess you don't want people switching a lot."
Speaker 1: "Switching shouldn't be a problem, though. I think the more they explore, the better it is, because the more they're engaged and the more they learn, and that's kind of our goal with this interface. So yeah."
Community Volunteer: "So yeah, so I guess my main thing: if you already have it somewhere on the page, then have the AI refer them to that page rather than just giving it to them straight out. If that makes sense. Because they'll do that and then they'll be like 'Oh, like what if I want to know more?' and then it's like you could have just gone to the page instead to learn more about it. You know? Yeah, that makes sense. So yeah, those are like my biggest things. But besides that, it's fine, it's perfect. And then this is just like the content that started messing up, yeah."
Speaker 1: "Yeah, that needs some work. And then... bookmarks. I just got back to it, yeah. I forgot. Okay, that's what bookmarks are for. And the labels—of course I need to update that. Yeah. All right, that's good."
Speaker 1: "Okay. Thank you so much for your time."
Community Volunteer: "No problem."